"""
Document Importer for Yuanqi Pulse Method Knowledge Base
å…ƒæ°”è„‰æ³•çŸ¥è¯†åº“æ–‡æ¡£å¯¼å…¥å·¥å…·

Supports:
- DOCX (Word documents)
- MD (Markdown files)
- PDF (PDF documents)

Usage:
    python scripts/import_documents.py --input /path/to/file.docx --type theory
    python scripts/import_documents.py --input /path/to/folder --batch
"""

import os
import sys
import json
import yaml
import argparse
from datetime import datetime
from typing import Dict, List, Any, Optional
import re

# Add src to path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


def read_docx(file_path: str) -> str:
    """
    è¯»å–DOCXæ–‡ä»¶å†…å®¹
    Read DOCX file content
    """
    try:
        from docx import Document
        doc = Document(file_path)
        
        content = []
        for para in doc.paragraphs:
            if para.text.strip():
                content.append(para.text)
        
        return "\n\n".join(content)
    except ImportError:
        print("è¯·å®‰è£… python-docx: pip install python-docx")
        return ""
    except Exception as e:
        print(f"è¯»å–DOCXå¤±è´¥: {e}")
        return ""


def read_markdown(file_path: str) -> str:
    """
    è¯»å–Markdownæ–‡ä»¶å†…å®¹
    Read Markdown file content
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        print(f"è¯»å–Markdownå¤±è´¥: {e}")
        return ""


def read_pdf(file_path: str) -> str:
    """
    è¯»å–PDFæ–‡ä»¶å†…å®¹
    Read PDF file content
    """
    try:
        import fitz  # PyMuPDF
        doc = fitz.open(file_path)
        
        content = []
        for page in doc:
            content.append(page.get_text())
        
        doc.close()
        return "\n\n".join(content)
    except ImportError:
        print("è¯·å®‰è£… PyMuPDF: pip install pymupdf")
        return ""
    except Exception as e:
        print(f"è¯»å–PDFå¤±è´¥: {e}")
        return ""


def read_document(file_path: str) -> str:
    """
    è‡ªåŠ¨è¯†åˆ«å¹¶è¯»å–æ–‡æ¡£
    Auto-detect and read document
    """
    ext = os.path.splitext(file_path)[1].lower()
    
    if ext == '.docx':
        return read_docx(file_path)
    elif ext in ['.md', '.markdown']:
        return read_markdown(file_path)
    elif ext == '.pdf':
        return read_pdf(file_path)
    else:
        print(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {ext}")
        return ""


def extract_sections(content: str) -> List[Dict[str, str]]:
    """
    ä»æ–‡æ¡£å†…å®¹æå–ç« èŠ‚
    Extract sections from document content
    """
    sections = []
    
    # å°è¯•æŒ‰æ ‡é¢˜åˆ†å‰²ï¼ˆæ”¯æŒ# æ ‡é¢˜ æˆ– ä¸€ã€äºŒã€ä¸‰ æ ¼å¼ï¼‰
    # Pattern for markdown headers or Chinese numbered sections
    patterns = [
        r'^#{1,3}\s+(.+)$',           # Markdown headers
        r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+[ã€.]\s*(.+)$',  # Chinese numbered
        r'^\d+[ã€.]\s*(.+)$',          # Arabic numbered
    ]
    
    lines = content.split('\n')
    current_section = {"title": "æ¦‚è¿°", "content": []}
    
    for line in lines:
        is_header = False
        for pattern in patterns:
            match = re.match(pattern, line.strip())
            if match:
                # Save previous section
                if current_section["content"]:
                    sections.append({
                        "title": current_section["title"],
                        "content": "\n".join(current_section["content"]).strip()
                    })
                # Start new section
                current_section = {"title": match.group(1).strip(), "content": []}
                is_header = True
                break
        
        if not is_header and line.strip():
            current_section["content"].append(line)
    
    # Save last section
    if current_section["content"]:
        sections.append({
            "title": current_section["title"],
            "content": "\n".join(current_section["content"]).strip()
        })
    
    return sections if sections else [{"title": "å…¨æ–‡", "content": content}]


def convert_to_theory(
    content: str, 
    source_file: str,
    category: str = "å…ƒæ°”è„‰æ³•ç†è®º"
) -> List[Dict[str, Any]]:
    """
    å°†æ–‡æ¡£å†…å®¹è½¬æ¢ä¸ºç†è®ºæ¡ç›®
    Convert document content to theory entries
    """
    sections = extract_sections(content)
    theories = []
    
    for i, section in enumerate(sections, 1):
        theory_id = f"YQ_THEORY_AUTO_{datetime.now().strftime('%Y%m%d')}_{i:03d}"
        
        theory = {
            "theory_id": theory_id,
            "category": category,
            "title": section["title"],
            "content": section["content"],
            "key_concepts": [],  # éœ€è¦åç»­æ ‡æ³¨
            "source": {
                "file": os.path.basename(source_file),
                "import_date": datetime.now().strftime("%Y-%m-%d"),
                "auto_imported": True
            },
            "needs_review": True  # æ ‡è®°éœ€è¦äººå·¥å®¡æ ¸
        }
        theories.append(theory)
    
    return theories


def convert_to_pulse_pattern(
    content: str,
    source_file: str
) -> List[Dict[str, Any]]:
    """
    å°†æ–‡æ¡£å†…å®¹è½¬æ¢ä¸ºè„‰è±¡æ¨¡å¼
    Convert document content to pulse patterns
    """
    sections = extract_sections(content)
    patterns = []
    
    for i, section in enumerate(sections, 1):
        pattern_id = f"YQ_PULSE_AUTO_{datetime.now().strftime('%Y%m%d')}_{i:03d}"
        
        pattern = {
            "pulse_pattern_id": pattern_id,
            "pattern_name": section["title"],
            "description": section["content"],
            "characteristics": {},  # éœ€è¦åç»­æ ‡æ³¨
            "key_features": [],
            "diagnostic_meaning": {},
            "source": {
                "file": os.path.basename(source_file),
                "import_date": datetime.now().strftime("%Y-%m-%d"),
                "auto_imported": True
            },
            "needs_review": True
        }
        patterns.append(pattern)
    
    return patterns


def save_imported_data(
    data: List[Dict],
    output_dir: str,
    prefix: str = "imported"
):
    """
    ä¿å­˜å¯¼å…¥çš„æ•°æ®
    Save imported data
    """
    os.makedirs(output_dir, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Save as YAML
    yaml_file = os.path.join(output_dir, f"{prefix}_{timestamp}.yaml")
    with open(yaml_file, 'w', encoding='utf-8') as f:
        yaml.dump(data, f, allow_unicode=True, default_flow_style=False)
    
    # Also save as JSON for easier processing
    json_file = os.path.join(output_dir, f"{prefix}_{timestamp}.json")
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    return yaml_file, json_file


def import_document(
    file_path: str,
    doc_type: str = "theory",
    output_dir: str = None
) -> Dict[str, Any]:
    """
    å¯¼å…¥å•ä¸ªæ–‡æ¡£
    Import a single document
    """
    print(f"\nğŸ“„ æ­£åœ¨å¯¼å…¥: {file_path}")
    
    # Read document
    content = read_document(file_path)
    if not content:
        return {"success": False, "error": "æ— æ³•è¯»å–æ–‡æ¡£å†…å®¹"}
    
    print(f"   è¯»å–æˆåŠŸ: {len(content)} å­—ç¬¦")
    
    # Convert based on type
    if doc_type == "theory":
        data = convert_to_theory(content, file_path)
        prefix = "theories"
    elif doc_type == "pulse":
        data = convert_to_pulse_pattern(content, file_path)
        prefix = "pulse_patterns"
    else:
        data = convert_to_theory(content, file_path)
        prefix = "general"
    
    print(f"   æå–æ¡ç›®: {len(data)} æ¡")
    
    # Save
    if output_dir is None:
        base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        output_dir = os.path.join(base_dir, "data", "corpus", "yuanqi_imported")
    
    yaml_file, json_file = save_imported_data(data, output_dir, prefix)
    
    print(f"   âœ… å·²ä¿å­˜: {yaml_file}")
    
    return {
        "success": True,
        "entries_count": len(data),
        "yaml_file": yaml_file,
        "json_file": json_file,
        "needs_review": True
    }


def batch_import(
    input_dir: str,
    doc_type: str = "theory",
    output_dir: str = None
) -> Dict[str, Any]:
    """
    æ‰¹é‡å¯¼å…¥ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡æ¡£
    Batch import all documents in a directory
    """
    results = []
    supported_extensions = ['.docx', '.md', '.markdown', '.pdf']
    
    for filename in os.listdir(input_dir):
        ext = os.path.splitext(filename)[1].lower()
        if ext in supported_extensions:
            file_path = os.path.join(input_dir, filename)
            result = import_document(file_path, doc_type, output_dir)
            result["file"] = filename
            results.append(result)
    
    success_count = sum(1 for r in results if r.get("success"))
    total_entries = sum(r.get("entries_count", 0) for r in results if r.get("success"))
    
    return {
        "files_processed": len(results),
        "success_count": success_count,
        "total_entries": total_entries,
        "results": results
    }


def main():
    parser = argparse.ArgumentParser(
        description="å…ƒæ°”è„‰æ³•çŸ¥è¯†åº“æ–‡æ¡£å¯¼å…¥å·¥å…·"
    )
    parser.add_argument(
        "--input", "-i",
        required=True,
        help="è¾“å…¥æ–‡ä»¶è·¯å¾„æˆ–ç›®å½•"
    )
    parser.add_argument(
        "--type", "-t",
        choices=["theory", "pulse", "case"],
        default="theory",
        help="æ–‡æ¡£ç±»å‹: theory(ç†è®º), pulse(è„‰è±¡), case(ç—…ä¾‹)"
    )
    parser.add_argument(
        "--output", "-o",
        help="è¾“å‡ºç›®å½• (é»˜è®¤: data/corpus/yuanqi_imported)"
    )
    parser.add_argument(
        "--batch", "-b",
        action="store_true",
        help="æ‰¹é‡å¯¼å…¥ç›®å½•ä¸­æ‰€æœ‰æ–‡æ¡£"
    )
    
    args = parser.parse_args()
    
    print("=" * 50)
    print("å…ƒæ°”è„‰æ³•çŸ¥è¯†åº“æ–‡æ¡£å¯¼å…¥å·¥å…·")
    print("=" * 50)
    
    if args.batch or os.path.isdir(args.input):
        result = batch_import(args.input, args.type, args.output)
        print(f"\nğŸ“Š å¯¼å…¥å®Œæˆ:")
        print(f"   å¤„ç†æ–‡ä»¶: {result['files_processed']}")
        print(f"   æˆåŠŸæ•°é‡: {result['success_count']}")
        print(f"   æ€»æ¡ç›®æ•°: {result['total_entries']}")
    else:
        result = import_document(args.input, args.type, args.output)
        if result["success"]:
            print(f"\nâœ… å¯¼å…¥æˆåŠŸ: {result['entries_count']} æ¡")
        else:
            print(f"\nâŒ å¯¼å…¥å¤±è´¥: {result.get('error')}")
    
    print("\nâš ï¸  æç¤º: è‡ªåŠ¨å¯¼å…¥çš„æ¡ç›®å·²æ ‡è®° needs_review=True")
    print("   è¯·äººå·¥å®¡æ ¸åæ›´æ–°åˆ°çŸ¥è¯†åº“ä»£ç ä¸­")


if __name__ == "__main__":
    main()
